{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22162/3812903467.py:14: DtypeWarning: Columns (15,16,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  incidents = pd.read_csv(INCIDENTS)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "import mapply\n",
    "mapply.init(n_workers=7, progressbar=True)\n",
    "\n",
    "\n",
    "# Read the data\n",
    "INCIDENTS = '../../dataset/data-raw/incidents.csv'\n",
    "POVERTYYEAY = '../../dataset/data-raw/povertyByStateYear.csv'\n",
    "STATEDISHOUSE = '../../dataset/data-raw/year_state_district_house.csv'\n",
    "\n",
    "incidents = pd.read_csv(INCIDENTS)\n",
    "poverty = pd.read_csv(POVERTYYEAY)\n",
    "state_district_house = pd.read_csv(STATEDISHOUSE)\n",
    "\n",
    "incidents['state'] = incidents['state'].str.upper()\n",
    "poverty['state'] = poverty['state'].str.upper()\n",
    "state_district_house['state'] = state_district_house['state'].str.upper()\n",
    "\n",
    "incidents['date_year'] = incidents['date'].str.split('-').str[0].astype(int)\n",
    "incidents['date_month'] = incidents['date'].str.split('-').str[1].astype(int)\n",
    "incidents['date_day'] = incidents['date'].str.split('-').str[2].astype(int)\n",
    "del incidents['date']\n",
    "\n",
    "incidents = incidents[['date_year', 'date_month', 'date_day', 'state', 'city_or_county', 'latitude', 'longitude', 'congressional_district', 'min_age_participants', 'avg_age_participants', 'max_age_participants', 'n_participants_child', 'n_participants_teen', 'n_participants_adult', 'n_males', 'n_females', 'n_killed', 'n_injured', 'n_arrested', 'n_unharmed', 'n_participants', 'incident_characteristics1']].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/Unipi/InProgress/DM/DM/lib/python3.11/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'Series.swapaxes' is deprecated and will be removed in a future version. Please use 'Series.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d2e6fb6d7164422be468c874b7ccade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/Unipi/InProgress/DM/DM/lib/python3.11/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'Series.swapaxes' is deprecated and will be removed in a future version. Please use 'Series.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b586548fef348e6a40646598e762e5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/Unipi/InProgress/DM/DM/lib/python3.11/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'Series.swapaxes' is deprecated and will be removed in a future version. Please use 'Series.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65cc929812f84447b000a453962e7817",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/Unipi/InProgress/DM/DM/lib/python3.11/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'Series.swapaxes' is deprecated and will be removed in a future version. Please use 'Series.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ada92cd7f5146aaae0c22678f96dad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/Unipi/InProgress/DM/DM/lib/python3.11/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'Series.swapaxes' is deprecated and will be removed in a future version. Please use 'Series.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62c6e4150f0b4c27bb6443448c78e9fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/Unipi/InProgress/DM/DM/lib/python3.11/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'Series.swapaxes' is deprecated and will be removed in a future version. Please use 'Series.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1be03f6414834ebcaf752e0cd05645fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set non-numeric values to NaN in columns supposed to be numeric\n",
    "\n",
    "objcols = incidents.select_dtypes(include=['object']).columns\n",
    "objcols = objcols.drop(['state', 'city_or_county', 'incident_characteristics1'])\n",
    "\n",
    "for col in objcols:\n",
    "    incidents[col] = incidents[col].mapply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/Unipi/InProgress/DM/DM/lib/python3.11/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'Series.swapaxes' is deprecated and will be removed in a future version. Please use 'Series.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b0acc4deab84792ab58baabba1e6d3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'OHIO-Hillsboro (Fairfax)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/simone/Unipi/InProgress/DM/DM/lib/python3.11/site-packages/multiprocess/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n                    ^^^^^^^^^^^^^^^^^^^\n  File \"/home/simone/Unipi/InProgress/DM/DM/lib/python3.11/site-packages/pathos/helpers/mp_helper.py\", line 15, in <lambda>\n    func = lambda args: f(*args)\n                        ^^^^^^^^\n  File \"/home/simone/Unipi/InProgress/DM/DM/lib/python3.11/site-packages/mapply/mapply.py\", line 122, in run_apply\n    return df_or_series.apply(func, args=args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/simone/Unipi/InProgress/DM/DM/lib/python3.11/site-packages/pandas/core/series.py\", line 4760, in apply\n    ).apply()\n      ^^^^^^^\n  File \"/home/simone/Unipi/InProgress/DM/DM/lib/python3.11/site-packages/pandas/core/apply.py\", line 1207, in apply\n    return self.apply_standard()\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/simone/Unipi/InProgress/DM/DM/lib/python3.11/site-packages/pandas/core/apply.py\", line 1287, in apply_standard\n    mapped = obj._map_values(\n             ^^^^^^^^^^^^^^^^\n  File \"/home/simone/Unipi/InProgress/DM/DM/lib/python3.11/site-packages/pandas/core/base.py\", line 921, in _map_values\n    return algorithms.map_array(arr, mapper, na_action=na_action, convert=convert)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/simone/Unipi/InProgress/DM/DM/lib/python3.11/site-packages/pandas/core/algorithms.py\", line 1814, in map_array\n    return lib.map_infer(values, mapper, convert=convert)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"lib.pyx\", line 2917, in pandas._libs.lib.map_infer\n  File \"/tmp/ipykernel_22162/67511068.py\", line 52, in <lambda>\n    cd_df['counts'] = cd_df['state_city'].mapply(lambda x: cd_vc[x])\n                                                           ~~~~~^^^\n  File \"/home/simone/Unipi/InProgress/DM/DM/lib/python3.11/site-packages/pandas/core/series.py\", line 1040, in __getitem__\n    return self._get_value(key)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/simone/Unipi/InProgress/DM/DM/lib/python3.11/site-packages/pandas/core/series.py\", line 1156, in _get_value\n    loc = self.index.get_loc(label)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/simone/Unipi/InProgress/DM/DM/lib/python3.11/site-packages/pandas/core/indexes/multi.py\", line 2925, in get_loc\n    loc = self._get_level_indexer(key, level=0)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/simone/Unipi/InProgress/DM/DM/lib/python3.11/site-packages/pandas/core/indexes/multi.py\", line 3303, in _get_level_indexer\n    raise KeyError(key)\nKeyError: 'OHIO-Hillsboro (Fairfax)'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/simone/Unipi/InProgress/DM/DataMining-2023/notebooks/simone/DC.ipynb Cell 3\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/simone/Unipi/InProgress/DM/DataMining-2023/notebooks/simone/DC.ipynb#W2sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39m# cd_df['congressional_district'] needs to be set to the most common value in the state_city\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/simone/Unipi/InProgress/DM/DataMining-2023/notebooks/simone/DC.ipynb#W2sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m cd_vc \u001b[39m=\u001b[39m cd_df\u001b[39m.\u001b[39mgroupby(\u001b[39m'\u001b[39m\u001b[39mstate_city\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m'\u001b[39m\u001b[39mcongressional_district\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalue_counts()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/simone/Unipi/InProgress/DM/DataMining-2023/notebooks/simone/DC.ipynb#W2sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m cd_df[\u001b[39m'\u001b[39m\u001b[39mcounts\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m cd_df[\u001b[39m'\u001b[39;49m\u001b[39mstate_city\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mmapply(\u001b[39mlambda\u001b[39;49;00m x: cd_vc[x])\n",
      "File \u001b[0;32m~/Unipi/InProgress/DM/DM/lib/python3.11/site-packages/mapply/mapply.py:127\u001b[0m, in \u001b[0;36mmapply\u001b[0;34m(df_or_series, func, axis, n_workers, chunk_size, max_chunks_per_worker, progressbar, args, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m isseries:\n\u001b[1;32m    125\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39maxis\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m axis\n\u001b[0;32m--> 127\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(\n\u001b[1;32m    128\u001b[0m     multiprocessing_imap(\n\u001b[1;32m    129\u001b[0m         partial(run_apply, func, args\u001b[39m=\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs),\n\u001b[1;32m    130\u001b[0m         dfs,\n\u001b[1;32m    131\u001b[0m         n_workers\u001b[39m=\u001b[39;49mn_workers,\n\u001b[1;32m    132\u001b[0m         progressbar\u001b[39m=\u001b[39;49mprogressbar,\n\u001b[1;32m    133\u001b[0m     ),\n\u001b[1;32m    134\u001b[0m )\n\u001b[1;32m    136\u001b[0m \u001b[39mif\u001b[39;00m isseries \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(results) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39msum\u001b[39m(\u001b[39mmap\u001b[39m(\u001b[39mlen\u001b[39m, results)) \u001b[39min\u001b[39;00m df_or_series\u001b[39m.\u001b[39mshape:\n\u001b[1;32m    137\u001b[0m     \u001b[39mreturn\u001b[39;00m concat(results, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Unipi/InProgress/DM/DM/lib/python3.11/site-packages/mapply/parallel.py:109\u001b[0m, in \u001b[0;36mmultiprocessing_imap\u001b[0;34m(func, iterable, n_workers, progressbar, args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m     stage \u001b[39m=\u001b[39m tqdm(stage, total\u001b[39m=\u001b[39mn_chunks)\n\u001b[1;32m    108\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 109\u001b[0m     \u001b[39myield from\u001b[39;00m stage\n\u001b[1;32m    110\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mException\u001b[39;00m, \u001b[39mKeyboardInterrupt\u001b[39;00m):\n\u001b[1;32m    111\u001b[0m     \u001b[39mif\u001b[39;00m pool:\n",
      "File \u001b[0;32m~/Unipi/InProgress/DM/DM/lib/python3.11/site-packages/tqdm/notebook.py:249\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    248\u001b[0m     it \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m(tqdm_notebook, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__iter__\u001b[39m()\n\u001b[0;32m--> 249\u001b[0m     \u001b[39mfor\u001b[39;49;00m obj \u001b[39min\u001b[39;49;00m it:\n\u001b[1;32m    250\u001b[0m         \u001b[39m# return super(tqdm...) will not catch exception\u001b[39;49;00m\n\u001b[1;32m    251\u001b[0m         \u001b[39myield\u001b[39;49;00m obj\n\u001b[1;32m    252\u001b[0m \u001b[39m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m~/Unipi/InProgress/DM/DM/lib/python3.11/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[39mfor\u001b[39;49;00m obj \u001b[39min\u001b[39;49;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[39myield\u001b[39;49;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m~/Unipi/InProgress/DM/DM/lib/python3.11/site-packages/multiprocess/pool.py:873\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m value\n\u001b[0;32m--> 873\u001b[0m \u001b[39mraise\u001b[39;00m value\n",
      "\u001b[0;31mKeyError\u001b[0m: 'OHIO-Hillsboro (Fairfax)'"
     ]
    }
   ],
   "source": [
    "# Infer the congressional district when missing as the most common one in the city\n",
    "# TO-OPTIMIZE: it would be faster to crack RSA-2048 on a TI-84\n",
    "def find_cd(row):\n",
    "    df = incidents[(incidents['state'] == row['state']) * (incidents['city_or_county'] == row['city_or_county'])]\n",
    "    # find the most common congressional district\n",
    "    vc = df['congressional_district'].value_counts()\n",
    "    if vc.empty:\n",
    "        row['congressional_district'] = np.nan\n",
    "        return row\n",
    "    cd = vc.idxmax()\n",
    "    row['congressional_district'] = cd\n",
    "    return row\n",
    "\n",
    "# set out-of-semnsible ranga values to NaN\n",
    "def sensibleValues(row):\n",
    "    # --- range checks ---\n",
    "    if row['date_year'] > 2020:\n",
    "        row['date_year'] = np.nan\n",
    "    if row['min_age_participants'] > 110 or row['min_age_participants'] < 0:\n",
    "        row['min_age_participants'] = np.nan\n",
    "    if row['avg_age_participants'] > 110 or row['avg_age_participants'] < 0:\n",
    "        row['avg_age_participants'] = np.nan\n",
    "    if row['max_age_participants'] > 110 or row['max_age_participants'] < 0:\n",
    "        row['max_age_participants'] = np.nan\n",
    "    # 103 is the maximum value of n_participants\n",
    "    if row['n_participants_child'] > 103 or row['n_participants_child'] < 0:\n",
    "        row['n_participants_child'] = np.nan\n",
    "    if row['n_participants_teen'] > 103 or row['n_participants_teen'] < 0:\n",
    "        row['n_participants_teen'] = np.nan\n",
    "    if row['n_participants_adult'] > 103 or row['n_participants_adult'] < 0:\n",
    "        row['n_participants_adult'] = np.nan\n",
    "    if row['n_killed'] > 103 or row['n_killed'] < 0:\n",
    "        row['n_killed'] = np.nan\n",
    "    if row['n_injured'] > 103 or row['n_injured'] < 0:\n",
    "        row['n_injured'] = np.nan\n",
    "    if row['n_arrested'] > 103 or row['n_arrested'] < 0:\n",
    "        row['n_arrested'] = np.nan\n",
    "    if row['n_unharmed'] > 103 or row['n_unharmed'] < 0:\n",
    "        row['n_unharmed'] = np.nan\n",
    "    # --- cogressional district ---\n",
    "    if pd.isna(row['congressional_district']):\n",
    "        find_cd(row)\n",
    "    return row\n",
    "\n",
    "\n",
    "# sincidents = incidents.mapply(sensibleValues, axis=1)\n",
    "cd_df = incidents[['state', 'city_or_county', 'congressional_district']].copy()\n",
    "cd_df['state_city'] = cd_df['state'] + \"-\" + cd_df['city_or_county']\n",
    "cd_df.head(1)\n",
    "# cd_df['congressional_district'] needs to be set to the most common value in the state_city\n",
    "cd_vc = cd_df.groupby('state_city')['congressional_district'].value_counts()\n",
    "cd_df['counts'] = cd_df['state_city'].mapply(lambda x: cd_vc[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/Unipi/InProgress/DM/DM/lib/python3.11/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06f50cd0ff6a4238bb49c392488adc43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE diff\n",
      "DONE dncidents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/Unipi/InProgress/DM/DM/lib/python3.11/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "991c7dd5601b4a80984917d0a5841582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE wncidents\n"
     ]
    }
   ],
   "source": [
    "# given the groups \n",
    "#   (n_participants)\n",
    "#   (n_males, n_females)\n",
    "#   (n_participants_child, n_participants_teen, n_participants_adult)\n",
    "#   (n_killed, n_injured, n_arrested, n_unharmed)\n",
    "# we find and solve inconsistencies between their sums, keeping the original proportions\n",
    "# Example:\n",
    "#   n_participants = 10\n",
    "#   n_participants_child\n",
    "#       + n_participants_teen\n",
    "#       + n_participants_adult = 10\n",
    "#   n_males = 2\n",
    "#   n_females = 6\n",
    "# then the most probable values (according to our assumptions) are groups that sum to 10 so:\n",
    "#   n_males => 3\n",
    "#   n_females => 7\n",
    "\n",
    "from random import randint\n",
    "\n",
    "# Don't ask, it works (maybe)\n",
    "def mf(row):\n",
    "    mf = row['n_males'] + row['n_females']\n",
    "    cta = row['n_participants_child'] + row['n_participants_teen'] + row['n_participants_adult']\n",
    "    kiau = row['n_killed'] + row['n_injured'] + row['n_arrested'] + row['n_unharmed']\n",
    "    p = row['n_participants']\n",
    "\n",
    "    if mf == cta == kiau == p:\n",
    "        return 0b0000\n",
    "    elif mf == cta == kiau:\n",
    "        return 0b0001\n",
    "    elif mf == cta == p:\n",
    "        return 0b0010\n",
    "    elif mf == kiau == p:\n",
    "        return 0b0100\n",
    "    elif cta == kiau == p:\n",
    "        return 0b1000\n",
    "    elif mf == p:\n",
    "        return 0b0110\n",
    "    elif cta == p:\n",
    "        return 0b1010\n",
    "    elif kiau == p:\n",
    "        return 0b1100\n",
    "    elif mf == cta:\n",
    "        return 0b0011\n",
    "    elif mf == kiau:\n",
    "        return 0b0101\n",
    "    elif cta == kiau:\n",
    "        return 0b1001\n",
    "    return 0b1111\n",
    "\n",
    "def perc_calc(vals: list):\n",
    "    s = np.sum(vals)\n",
    "    if s == 0:\n",
    "        return 1/len(vals)\n",
    "    return vals[0] / s\n",
    "\n",
    "    \n",
    "def nannifyErrors(row):\n",
    "    err_bits = mf(row)\n",
    "    err_p = err_bits & 0b0001\n",
    "    err_mf = err_bits & 0b1000\n",
    "    err_cta = err_bits & 0b0100\n",
    "    err_kiau = err_bits & 0b0010\n",
    "\n",
    "    ref = row['n_participants'] if not err_p else \\\n",
    "        row['n_males'] + row['n_females'] if not err_mf else \\\n",
    "        row['n_participants_child'] + row['n_participants_teen'] + row['n_participants_adult'] if not err_cta else \\\n",
    "        row['n_killed'] + row['n_injured'] + row['n_arrested'] + row['n_unharmed'] if not err_kiau else \\\n",
    "        np.nan\n",
    "\n",
    "\n",
    "    if err_p:\n",
    "        row['n_participants'] = ref\n",
    "    if err_mf:\n",
    "        p_m = perc_calc([row['n_males'], row['n_females']])\n",
    "        row['n_males'] = np.round(ref * p_m)\n",
    "        row['n_females'] = np.round(ref * (1 - p_m))\n",
    "        diff = ref - (row['n_males'] + row['n_females'])\n",
    "        if diff != 0:\n",
    "            # With 1/2 probability add the difference to males of females\n",
    "            row['n_males' if randint(0,1) else 'n_females'] += diff\n",
    "    if err_cta:\n",
    "        p_c = perc_calc([row['n_participants_child'], row['n_participants_teen'], row['n_participants_adult']])\n",
    "        p_t = perc_calc([row['n_participants_teen'], row['n_participants_child'], row['n_participants_adult']])\n",
    "        row['n_participants_child'] = np.round(ref * p_c)\n",
    "        row['n_participants_teen'] = np.round(ref * p_t)\n",
    "        row['n_participants_adult'] = np.round(ref * (1 - p_c - p_t))\n",
    "        diff = ref - (row['n_participants_child'] + row['n_participants_teen'] + row['n_participants_adult'])\n",
    "        if diff != 0:\n",
    "            # With 1/3 probability, add the difference to child, teen or adult\n",
    "            row['n_participants_child' if randint(0,2) == 0 else 'n_participants_teen' if randint(0,1) else 'n_participants_adult'] += diff\n",
    "    if err_kiau:\n",
    "        p_k = perc_calc([row['n_killed'], row['n_injured'], row['n_arrested'], row['n_unharmed']])\n",
    "        p_i = perc_calc([row['n_injured'], row['n_killed'], row['n_arrested'], row['n_unharmed']])\n",
    "        p_a = perc_calc([row['n_arrested'], row['n_killed'], row['n_injured'], row['n_unharmed']])\n",
    "        row['n_killed'] = np.round(ref * p_k)\n",
    "        row['n_injured'] = np.round(ref * p_i)\n",
    "        row['n_arrested'] = np.round(ref * p_a)\n",
    "        row['n_unharmed'] = np.round(ref * (1 - p_k - p_i - p_a))\n",
    "        diff = ref - (row['n_killed'] + row['n_injured'] + row['n_arrested'] + row['n_unharmed'])\n",
    "        if diff != 0:\n",
    "            # With 1/4 probability, add the difference to killed, injured, arrested or unharmed\n",
    "            row['n_killed' if randint(0,3) == 0 else 'n_injured' if randint(0,2) == 0 else 'n_arrested' if randint(0,1) else 'n_unharmed'] += diff\n",
    "    return row\n",
    "\n",
    "\n",
    "\n",
    "diff = sincidents.mapply(mf, axis=1)\n",
    "print('DONE diff')\n",
    "# incidents without problems\n",
    "dncidents = sincidents[diff == 0b0000]\n",
    "print('DONE dncidents')\n",
    "# incidents with problems\n",
    "wncidents = sincidents[diff != 0b0000].mapply(nannifyErrors, axis=1)\n",
    "print('DONE wncidents')\n",
    "\n",
    "# dncidents = incidents.iloc[0:10000].apply(nannifyErrors, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge wncidents with dncidents\n",
    "wdincidents = pd.concat([wncidents, dncidents], ignore_index=False)\n",
    "# shuffle the rows to mix the incidents with problems (wncidents) with the others (dncidents)\n",
    "wdincidents = wdincidents.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+--------------+------------+---------+------------------+------------+-------------+--------------------------+------------------------+------------------------+------------------------+------------------------+-----------------------+------------------------+-----------+-------------+------------+-------------+--------------+--------------+------------------+-----------------------------+\n",
      "|    |   date_year |   date_month |   date_day |   state |   city_or_county |   latitude |   longitude |   congressional_district |   min_age_participants |   avg_age_participants |   max_age_participants |   n_participants_child |   n_participants_teen |   n_participants_adult |   n_males |   n_females |   n_killed |   n_injured |   n_arrested |   n_unharmed |   n_participants |   incident_characteristics1 |\n",
      "|----+-------------+--------------+------------+---------+------------------+------------+-------------+--------------------------+------------------------+------------------------+------------------------+------------------------+-----------------------+------------------------+-----------+-------------+------------+-------------+--------------+--------------+------------------+-----------------------------|\n",
      "|  0 |       23031 |            0 |          0 |       0 |                0 |       7923 |        7923 |                      425 |                  92296 |                  92300 |                  92299 |                  42167 |                 42167 |                  42167 |     36519 |       36519 |      27818 |       27818 |        27818 |        27818 |            26290 |                         326 |\n",
      "+----+-------------+--------------+------------+---------+------------------+------------+-------------+--------------------------+------------------------+------------------------+------------------------+------------------------+-----------------------+------------------------+-----------+-------------+------------+-------------+--------------+--------------+------------------+-----------------------------+\n",
      "+----+-------------+--------------+------------+---------+------------------+------------+-------------+--------------------------+------------------------+------------------------+------------------------+------------------------+-----------------------+------------------------+-----------+-------------+------------+-------------+--------------+--------------+------------------+-----------------------------+\n",
      "|    |   date_year |   date_month |   date_day |   state |   city_or_county |   latitude |   longitude |   congressional_district |   min_age_participants |   avg_age_participants |   max_age_participants |   n_participants_child |   n_participants_teen |   n_participants_adult |   n_males |   n_females |   n_killed |   n_injured |   n_arrested |   n_unharmed |   n_participants |   incident_characteristics1 |\n",
      "|----+-------------+--------------+------------+---------+------------------+------------+-------------+--------------------------+------------------------+------------------------+------------------------+------------------------+-----------------------+------------------------+-----------+-------------+------------+-------------+--------------+--------------+------------------+-----------------------------|\n",
      "|  0 |       22987 |            0 |          0 |       0 |                0 |       7123 |        7123 |                        0 |                  65893 |                  65897 |                  65896 |                  15828 |                 15828 |                  15828 |     10205 |       10205 |       1514 |        1514 |         1514 |         1514 |                0 |                           0 |\n",
      "+----+-------------+--------------+------------+---------+------------------+------------+-------------+--------------------------+------------------------+------------------------+------------------------+------------------------+-----------------------+------------------------+-----------+-------------+------------+-------------+--------------+--------------+------------------+-----------------------------+\n",
      "0.8861759785044039\n",
      "+----+-------------+--------------+------------+---------+------------------+------------+-------------+--------------------------+------------------------+------------------------+------------------------+------------------------+-----------------------+------------------------+-----------+-------------+------------+-------------+--------------+--------------+------------------+-----------------------------+-------------+\n",
      "|    |   date_year |   date_month |   date_day |   state |   city_or_county |   latitude |   longitude |   congressional_district |   min_age_participants |   avg_age_participants |   max_age_participants |   n_participants_child |   n_participants_teen |   n_participants_adult |   n_males |   n_females |   n_killed |   n_injured |   n_arrested |   n_unharmed |   n_participants |   incident_characteristics1 |   timestamp |\n",
      "|----+-------------+--------------+------------+---------+------------------+------------+-------------+--------------------------+------------------------+------------------------+------------------------+------------------------+-----------------------+------------------------+-----------+-------------+------------+-------------+--------------+--------------+------------------+-----------------------------+-------------|\n",
      "|  0 |           0 |            0 |          0 |       0 |                0 |          0 |           0 |                        0 |                      0 |                      0 |                      0 |                      0 |                     0 |                      0 |         0 |           0 |          0 |           0 |            0 |            0 |                0 |                           0 |           0 |\n",
      "+----+-------------+--------------+------------+---------+------------------+------------+-------------+--------------------------+------------------------+------------------------+------------------------+------------------------+-----------------------+------------------------+-----------+-------------+------------+-------------+--------------+--------------+------------------+-----------------------------+-------------+\n"
     ]
    }
   ],
   "source": [
    "cincidents = wdincidents.copy()\n",
    "\n",
    "print(tabulate(pd.DataFrame(cincidents.isnull().sum(axis=0)).T, headers='keys', tablefmt='psql'))\n",
    "\n",
    "# cincidents['n_nan'] = cincidents.isnull().sum(axis=1)\n",
    "# cincidents['n_nan'].value_counts().sort_index().plot.bar()\n",
    "\n",
    "mfdslkmfdslk = cincidents[(cincidents[['n_participants', 'n_males', 'n_females', 'n_participants_child', 'n_participants_teen', 'n_participants_adult', 'n_killed', 'n_injured', 'n_arrested', 'n_unharmed']].isnull().sum(axis=1) == 10)]\n",
    "\n",
    "# 425 bad rows\n",
    "cincidents = cincidents[~cincidents['congressional_district'].isnull()]\n",
    "# 326 bad rows\n",
    "cincidents = cincidents[~cincidents['incident_characteristics1'].isnull()]\n",
    "# remove all rows where the n_participants groups are all NaN\n",
    "cincidents = cincidents[~(cincidents[['n_participants', 'n_males', 'n_females', 'n_participants_child', 'n_participants_teen', 'n_participants_adult', 'n_killed', 'n_injured', 'n_arrested', 'n_unharmed']].isnull().sum(axis=1) == 10)]\n",
    "print(tabulate(pd.DataFrame(cincidents.isnull().sum(axis=0)).T, headers='keys', tablefmt='psql'))\n",
    "# drop duplicates\n",
    "cincidents = cincidents.drop_duplicates()\n",
    "\n",
    "print(cincidents.shape[0] / incidents.shape[0])\n",
    "\n",
    "# TEMPORARY: Fix all NaNs with the median of the column\n",
    "# for col in ['n_participants', 'n_males', 'n_females', 'n_participants_child', 'n_participants_teen', 'n_participants_adult', 'n_killed', 'n_injured', 'n_arrested', 'n_unharmed']:\n",
    "for col in cincidents.select_dtypes(include=['float64']).columns:\n",
    "    median = cincidents[col].median()\n",
    "    cincidents[col] = cincidents[col].fillna(median)\n",
    "\n",
    "\n",
    "# set as number of days since 2010-01-01\n",
    "cincidents['timestamp'] = (pd.to_datetime(cincidents[['date_year', 'date_month', 'date_day']].astype(int).astype(str).apply(lambda x: '-'.join(x), axis=1)).astype(int) - pd.to_datetime(['2010-01-01']).astype(int)[0]) / 86400000000000\n",
    "\n",
    "# cincidents = cincidents.drop(['date_year', 'date_month', 'date_day'], axis=1)\n",
    "print(tabulate(pd.DataFrame(cincidents.isnull().sum(axis=0)).T, headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/simone/Unipi/InProgress/DM/DataMining-2023/notebooks/simone/DC.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/simone/Unipi/InProgress/DM/DataMining-2023/notebooks/simone/DC.ipynb#X12sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m merged \u001b[39m=\u001b[39m merged\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39myear\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/simone/Unipi/InProgress/DM/DataMining-2023/notebooks/simone/DC.ipynb#X12sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m merged\u001b[39m.\u001b[39misnull()\u001b[39m.\u001b[39msum(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/simone/Unipi/InProgress/DM/DataMining-2023/notebooks/simone/DC.ipynb#X12sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m a \u001b[39m=\u001b[39m merged[merged[\u001b[39m'\u001b[39;49m\u001b[39mparty\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49misnull()]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/simone/Unipi/InProgress/DM/DataMining-2023/notebooks/simone/DC.ipynb#X12sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m b \u001b[39m=\u001b[39m merged[merged[\u001b[39m'\u001b[39m\u001b[39mcongressional_district\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/Unipi/InProgress/DM/DM/lib/python3.11/site-packages/pandas/core/series.py:5488\u001b[0m, in \u001b[0;36mSeries.isnull\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5483\u001b[0m \u001b[39m@doc\u001b[39m(NDFrame\u001b[39m.\u001b[39misna, klass\u001b[39m=\u001b[39m_shared_doc_kwargs[\u001b[39m\"\u001b[39m\u001b[39mklass\u001b[39m\u001b[39m\"\u001b[39m])  \u001b[39m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m   5484\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39misnull\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Series:\n\u001b[1;32m   5485\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   5486\u001b[0m \u001b[39m    Series.isnull is an alias for Series.isna.\u001b[39;00m\n\u001b[1;32m   5487\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5488\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49misnull()\n",
      "File \u001b[0;32m~/Unipi/InProgress/DM/DM/lib/python3.11/site-packages/pandas/core/generic.py:8467\u001b[0m, in \u001b[0;36mNDFrame.isnull\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   8465\u001b[0m \u001b[39m@doc\u001b[39m(isna, klass\u001b[39m=\u001b[39m_shared_doc_kwargs[\u001b[39m\"\u001b[39m\u001b[39mklass\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m   8466\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39misnull\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Self:\n\u001b[0;32m-> 8467\u001b[0m     \u001b[39mreturn\u001b[39;00m isna(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39misnull\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Unipi/InProgress/DM/DM/lib/python3.11/site-packages/pandas/core/dtypes/missing.py:178\u001b[0m, in \u001b[0;36misna\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39misna\u001b[39m(obj: \u001b[39mobject\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m \u001b[39m|\u001b[39m npt\u001b[39m.\u001b[39mNDArray[np\u001b[39m.\u001b[39mbool_] \u001b[39m|\u001b[39m NDFrame:\n\u001b[1;32m    102\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[39m    Detect missing values for an array-like object.\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[39m    Name: 1, dtype: bool\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 178\u001b[0m     \u001b[39mreturn\u001b[39;00m _isna(obj)\n",
      "File \u001b[0;32m~/Unipi/InProgress/DM/DM/lib/python3.11/site-packages/pandas/core/dtypes/missing.py:216\u001b[0m, in \u001b[0;36m_isna\u001b[0;34m(obj, inf_as_na)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[39mreturn\u001b[39;00m _isna_array(obj\u001b[39m.\u001b[39m_values, inf_as_na\u001b[39m=\u001b[39minf_as_na)\n\u001b[1;32m    215\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, ABCSeries):\n\u001b[0;32m--> 216\u001b[0m     result \u001b[39m=\u001b[39m _isna_array(obj\u001b[39m.\u001b[39;49m_values, inf_as_na\u001b[39m=\u001b[39;49minf_as_na)\n\u001b[1;32m    217\u001b[0m     \u001b[39m# box\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     result \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_constructor(result, index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex, name\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mname, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Unipi/InProgress/DM/DM/lib/python3.11/site-packages/pandas/core/dtypes/missing.py:292\u001b[0m, in \u001b[0;36m_isna_array\u001b[0;34m(values, inf_as_na)\u001b[0m\n\u001b[1;32m    290\u001b[0m     result \u001b[39m=\u001b[39m _isna_recarray_dtype(values, inf_as_na\u001b[39m=\u001b[39minf_as_na)\n\u001b[1;32m    291\u001b[0m \u001b[39melif\u001b[39;00m is_string_or_object_np_dtype(values\u001b[39m.\u001b[39mdtype):\n\u001b[0;32m--> 292\u001b[0m     result \u001b[39m=\u001b[39m _isna_string_dtype(values, inf_as_na\u001b[39m=\u001b[39;49minf_as_na)\n\u001b[1;32m    293\u001b[0m \u001b[39melif\u001b[39;00m dtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mmM\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    294\u001b[0m     \u001b[39m# this is the NaT pattern\u001b[39;00m\n\u001b[1;32m    295\u001b[0m     result \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mview(\u001b[39m\"\u001b[39m\u001b[39mi8\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m==\u001b[39m iNaT\n",
      "File \u001b[0;32m~/Unipi/InProgress/DM/DM/lib/python3.11/site-packages/pandas/core/dtypes/missing.py:313\u001b[0m, in \u001b[0;36m_isna_string_dtype\u001b[0;34m(values, inf_as_na)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    312\u001b[0m     \u001b[39mif\u001b[39;00m values\u001b[39m.\u001b[39mndim \u001b[39min\u001b[39;00m {\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[0;32m--> 313\u001b[0m         result \u001b[39m=\u001b[39m libmissing\u001b[39m.\u001b[39;49misnaobj(values, inf_as_na\u001b[39m=\u001b[39;49minf_as_na)\n\u001b[1;32m    314\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    315\u001b[0m         \u001b[39m# 0-D, reached via e.g. mask_missing\u001b[39;00m\n\u001b[1;32m    316\u001b[0m         result \u001b[39m=\u001b[39m libmissing\u001b[39m.\u001b[39misnaobj(values\u001b[39m.\u001b[39mravel(), inf_as_na\u001b[39m=\u001b[39minf_as_na)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Merge with poverty\n",
    "# poverty header: [state,year,povertyPercentage]\n",
    "merged = cincidents.merge(poverty, how='left', left_on=['state', 'date_year'], right_on=['state', 'year'])\n",
    "merged = merged.drop(columns=['year'])\n",
    "\n",
    "# Merge with state_district_house\n",
    "# state_district_house header: [year,state,congressional_district,party,candidatevotes,totalvotes]\n",
    "# state_district_house rows are only for even years but we have incidents for all years\n",
    "merged['congressional_district'] = merged['congressional_district'].mapply(lambda x: 1 if x == 0 else x)\n",
    "state_district_house['congressional_district'] = state_district_house['congressional_district'].mapply(lambda x: 1 if x == 0 else x)\n",
    "stete_district_house_odd = state_district_house.copy()\n",
    "stete_district_house_odd['year'] = state_district_house['year'] + 1\n",
    "state_district_house = pd.concat([state_district_house, stete_district_house_odd], ignore_index=True).reset_index(drop=True)\n",
    "\n",
    "merged = merged.merge(state_district_house, how='left', left_on=['state', 'date_year', 'congressional_district'], right_on=['state', 'year', 'congressional_district'])\n",
    "merged = merged.drop(columns=['year'])\n",
    "\n",
    "merged.isnull().sum(axis=0)\n",
    "a = merged[merged['party'].isnull()]\n",
    "b = merged[merged['congressional_district'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
